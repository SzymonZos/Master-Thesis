\section{Solution to the problem}

\subsection{Proposed algorithm}

Taking into consideration existing solutions mentioned in \nameref{ch:problem} it was decided to
implement several extensions of the JPEG 2000 standard, Part 2. Moreover, proposed algorithm
was designed to be parallelized. Such decision improves runtime performance especially in applications
that require processing of great number of images. As it was announced in \nameref{ch:intro}, the standard
way of computing discrete wavelet transform in the Part 1 of the JPEG 2000 standard is to decompose the
image into sub-bands using a pair of low- and high-pass filters. This decomposition is performed both in
vertical and horizontal directions. Moreover, it is applied multiple times across whole processing tree.

Vast majority of available extensions was mentioned in \nameref{sec:part2_jpeg2000}. It was decided to choose
\nameref{sec:arbitrary_decomposition} and \nameref{sec:arbitrary_wavelet_transform} in the planning phase of
thesis development. As it was shown in the mentioned beforehand chapters, arbitrary decomposition
extension creates a possibility of splitting the image into sub-bands of different shapes. The latter feature,
i.e. arbitrary wavelet transform breaks strict selection rule of filters pair. With the help of these
extensions and carefully chosen JPEG 2000 coder estimation process it is possible to adaptively choose
best possible variant for the given image.

The workflow of the presented solution is as follows.

\begin{itemize}
    \item The image is chosen by the user in the command line interface.
    \item The image is transformed to grayscale or left in RGB space upon choice of the user.
    \item The scheduler determines number of present hardware threads able to run program.
    \item Each thread dispatches possible combination of decomposition from precomputed look up table.
    \item The chain of selected DWTs is calculated in the context of each thread.
    \item During decomposition process entropy of image is calculated and stored for later usage.
    \item Minimal entropy is chosen after finish of the above mentioned calculations.
    \item Process is repeated for other filter pairs.
    \item Global minimum entropy is chosen and the best combination is shown to the user.
\end{itemize}

\subsection{Different variants of DWT decomposition} \label{sec:dwt_decompositions}

As it was described in \nameref{sec:arbitrary_wavelet_transform} the Part 2 of JPEG 2000 standard allows to perform
multiple modifications of decomposition even in the same step of DWT. The \nameref{sec:kakadu} solution supports
such extensive set of DWT variants. However, in this solution the combinations were narrowed to the most
generic case. Moreover, the depth of discrete wavelet transform chain was limited to 5.

The chosen heuristic consists of four possible operation which are applied on the certain DWT level.
The first one is a transformation compliant with Part 1 of the JPEG 2000 standard, i.e. 2D DWT. Therefore, in a result
of such operation four sub-bands are created. The sub-band which was two time filtered with low-pass filter
is once again transformed in the next DWT level. Another two options imply on transforming given image only
row-wise or column-wise by applying 1D DWT. The low-pass filtered image is once again promoted to next DWT operations.
Last possible transformation is basically no operation and resignation from another calculations

\subsection{Selected filters}

Although the design of the application is flexible in terms of selecting the pair of filters, it was decided
to limit initial research to three options. The first option is Part 1 compliant solution, i.e. 5/3 LeGall filter.
The other two filters are Haar (as a special case of the Daubechies wavelet, the Haar wavelet is also known as ``db1'')
and 13x7 biorthogonal wavelet.

TODO: Add some images and coefs.

\subsection{Entropy as JPEG 2000 coder estimator}

The entropy can be understood as the average level of ``information'', ``surprise'' or ``uncertainty'' in the variable's
possible outcomes. It also called a Shannon entropy due to being introduced in the paper ``A Mathematical Theory of Communication'' \cite{entropy_wiki}.
Given a discrete random variable $X$ with possible outcomes $x_{1},\dots,x_{n}$ that occur with probability
$P(x_{1}),\dots,P(x_{n})$, the entropy of $X$ is defined as in the formula \ref{eq:entropy} \cite{entropy}.
\begin{equation}
    H(X)=-\sum_{i=1}^{n}P(x_{i})logP(x_{i})
\label{eq:entropy}
\end{equation}
The base of logarithm mentioned in the formula \ref{eq:entropy} can vary across different applications. Base 2 is used
in this application. Its unit is called bits or ``shannons'', while base 10 gives units called ``dits'' and base $e$
natural units - ``nats'' \cite{entropy_wiki}. Moreover, it assumed that $0*log_{2}0=0$ in the process of entropy calculation.

Claude Shannon originally described entropy as part of his theory of communication. A data communication system
was characterized by three elements, i.e. a source of data, a communication channel and a receiver. Shannon described
the main function of receiver as ability to identify what data was generated by the given source. Such determination
is based only on the signal that was received through the channel of communication. Various ways of encoding,
compressing and transmitting messages from a data source were considered in Shannon's theory. The entropy was described
as absolute mathematical limit on how well data from the source can losslessly compressed and sent through perfectly
noiseless channel \cite{entropy_wiki}.

The memoryless entropy was chosen as an estimator of real compression results. Although it is not ideal estimation,
such operation is good enough as results are proportional to these from JPEG 2000 coder \cite{entropy}.
Therefore entropy can be used just to determine choice between variants of DWT as described in \ref{sec:dwt_decompositions}.
However, such calculation of entropy can achieve not satisfying results for low filtered images.
The reason for such behavior lays in the very different characteristics of these images. The actual JPEG 2000 coder
is not context-free as memoryless entropy. High filtered images are free of such error due to context neutralizing
nature of such filters. To achieve same effect for low filtered images several methods were tested.
During tests it turned out that best results are achieved using difference between certain pixel and its left neighbor.

TODO: write something about other methods

\section{Implementation details}

\subsection{Chosen programming language}

The features of given language exist to provide support for certain styles of programming. An individual
language feature should never be perceived as a solution. Bjarne Stroustrup in his book ``The C++ Programming Language''
suggests that language feature should be rather perceived as one building brick from a varied set which can
furtherly combined to express desired solutions \cite{cpp_language_bjarne}. Moreover, there are listed
basic requirements for design and programming:
\begin{itemize}
    \item Ideas shall directly be expressed in the code.
    \item Independent ideas shall be independently expressed in the code.
    \item Relationships shall be represented directly in code among directly in the code among other ideas.
    \item Expressed ideas shall be combined freely, where and only where combinations make sense.
    \item Simple ideas shall be expressed simply \cite{cpp_language_bjarne}.
\end{itemize}

Given that the C++ programming language supports four styles of programming:
\begin{itemize}
    \item Procedural programming.
    \item Abstraction of data.
    \item Object-oriented programming.
    \item Generic programming.
\end{itemize}
Items in the list are not exclusive to each other. Moreover, as combination of chosen features
more desirable solution can be achieved. There are several aspects that make software application
successful, e.g. maintainability, readability, small size and fast time execution. To achieve it
for a nontrivial problem these styles are recommended to use in conjunction \cite{cpp_language_bjarne}.

The most notable solution present in the scope of algorithm implementation is generic programming.
This type of programming is focused on the design, implementation and runtime use of general purpose
algorithms. By ``general'' it is understood possibility of accepting variety of types by the algorithm.
However, these types have to meet specified requirements of the given algorithm. The main support
of generic programming in the C++ programming language is $template$ which provide static,
i.e. compile-time polymorphism \cite{cpp_language_bjarne}.

The C++11 standard introduced for the first time a thread library. It is heavily
influenced by its ancestors, e.g. Boost Thread Library. These Boost classes were the primary model
on which the standard library is based. Moreover, many entities share same names and structure \cite{cpp_concurrency}.
However, there are some disadvantages in the standard threading library. Notable features are
missing in comparison with other threading APIs, i.e. ``pthreads'' and Windows threads.
The reason lays in the extensive set of constraints on compiler implementers. Nevertheless,
multithreaded applications can be developed with standard behavior across all platforms.
This enables a solid foundation on which libraries utilizing parallelism can be built.
The concurrency elements of the Standard Library like futures, threads, mutexes and atomics
are the important but not the only available solutions for developing concurrent C++ software \cite{cpp_meyers}.

The thread-based programming provide higher level of abstraction in comparison to task-based one.
Therefore it makes thread management easier. However, there are multiple types of ``thread''
that can be encountered in concurrent C++ software:
\begin{itemize}
    \item Hardware threads are the ones that actually perform computation. Machine architectures
    offer one or more hardware threads per CPU core.
    \item Software threads, also known as system threads are the ones that operating system manages
    across all processes. The scheduler prepares their execution on hardware threads. Therefore, it
    is possible to create more software threads than the hardware ones. The motivation is execution
    of unblocked threads when the other ones are blocked, e.g. wait for mutex.
    \item $std::threads$ are C++ objects that act like handles to underlying software threads.
    Standard thread can correspond to nothing so it represents ``null'' handle. There are several scenarios
    leading to this behavior. Default-constructed objects with no function to execute are the first
    example. The other ones include object state after being moved from, joined and detached thread \cite{cpp_meyers}.
\end{itemize}

\subsection{Build environment}

The build environment is setup around CMake. This software is open-sourced, cross-platform tool
designed to not only build but also test and package various applications. CMake is aimed to
control the compilation process of given software using compiler and platform agnostic configuration
text files. Such setup allows to generate platform native tools to build project, e.g. Makefiles
for GNU/Linux or nmake for Windows. Moreover, it is possible to generate Visual Studio project
files with the help of CMake. This software is also capable of generating wrappers, creating
both dynamic and static libraries and building executables in arbitrary combinations. Another
viable CMake feature is its caching system. Upon running build such text file is generated
and is ready to be investigated using graphical editor. The located files, libraries, executables
and optional build directives are placed in the cache \cite{cmake}.

\begin{listing}[htb]
\begin{minted}[linenos, breaklines]{cmake}
project(jpeg2000_src)
add_subdirectory(dwt)
if(BUILD_EXTERNALS AND EXISTS ${JP3D_PATH})
    add_subdirectory(${JP3D_PATH})
endif()

set(SOURCES
    demo_dwt.cpp
    demo_queue.cpp
    demo_opencv.cpp
    arg_parser.cpp
    main.cpp
)
add_executable(jpeg2000 ${SOURCES})
set_target_properties(jpeg2000 PROPERTIES COMPILE_FLAGS "-save-temps")
if(BUILD_EXTERNALS)
    target_include_directories(jpeg2000 SYSTEM PRIVATE
        ${OPENCV_PATH}/modules/core/include
        ${OPENCV_PATH}/modules/imgcodecs/include
        ${OPENCV_PATH}/modules/imgproc/include
        ${CMAKE_BINARY_DIR} # OpenCV is looking for opencv2/opencv_modules.hpp
        ${CXXOPTS_PATH}/include
    )
    target_compile_definitions(jpeg2000 PRIVATE BUILD_OPENCV)
endif()
target_include_directories(jpeg2000 SYSTEM PRIVATE
    ${CMAKE_SOURCE_DIR}
    ${TIMER_PATH}
)
target_link_libraries(jpeg2000 PRIVATE
    dwt
    cxxopts
)
if(BUILD_EXTERNALS)
    target_link_libraries(jpeg2000 PRIVATE
        opencv_core
        opencv_imgcodecs
        opencv_imgproc
    )
    if(EXISTS ${JP3D_PATH})
        target_link_libraries(jpeg2000 PRIVATE jp3d)
    endif()
endif()
\end{minted}
\caption{Sample CMakeLists.txt file}
\label{lst:sample_cmake_file}
\end{listing}

The CMake tool is arranged to support complex structure of directory hierarchies and applications
which can be dependent on other libraries. The other complex scenario that can be handled by CMake
is building the executables in the specific order to generate code which is compiled and linked
into eventual application. The building processes is managed by CMakeLists.txt files that have
to be located in each directory containing source files. The sample CMakeLists.txt file can be
seen at the listing \ref{lst:sample_cmake_file}. This software provides not only predefined commands
but also a possibility of adding user functions.

\subsection{DWT interface}

\subsection{Testing}

The testing, especially test driven development takes essential place in the software development
process. For the purpose of checking correctness of proposed discrete wavelet transform algorithm
``PyWavelets'' (Wavelet Transforms in Python) software was used as the reference model \cite{pywavelets}.
Thanks to pybind11 \cite{pybind11} C++ was exposed to the Python and then tested using pytest framework.
The first one is a lightweight header-only library that synergizes both Python and C++. The main purpose
is to create Python bindings for existing C++ code. Boilerplate code is minimized thanks to inferring
type information using introspection during compile-time \cite{pywavelets}. On the other hand pytest framework makes
writing small and readable tests easier. Moreover, it can scale up to support complex functional
testing for other libraries and applications \cite{pytest}.


% What fixtures are
% In testing, a fixture provides a defined, reliable and consistent context for the tests. This could include environment (for example a database configured with known parameters) or content (such as a dataset).

% Fixtures define the steps and data that constitute the arrange phase of a test (see Anatomy of a test). In pytest, they are functions you define that serve this purpose. They can also be used to define a test’s act phase; this is a powerful technique for designing more complex tests.

% The services, state, or other operating environments set up by fixtures are accessed by test functions through arguments. For each fixture used by a test function there is typically a parameter (named after the fixture) in the test function’s definition.

% We can tell pytest that a particular function is a fixture by decorating it with @pytest.fixture. Here’s a simple example of what a fixture in pytest might look like:

\subsection{Parallel for}

\begin{listing}[htb]
\begin{minted}[linenos, breaklines]{cpp}
#ifndef JPEG2000_PARALLEL_FOR_HPP
#define JPEG2000_PARALLEL_FOR_HPP

#include "config.hpp"

#include <concepts>
#include <functional>
#include <thread>
#include <vector>

namespace mgr {
namespace detail {

// clang-format off
template<typename Func, typename... Args>
// std::invocable<Func, Args...> should really be used in conjunction
// enable it with the release of libc++13 (support of <concepts> header)
concept no_returnable = std::same_as<std::invoke_result_t<Func, Args...>, void>;

template<typename Func, typename... Args>
concept returnable = !no_returnable<Func, Args...>;
// clang-format on

template<typename Func>
void parallel_for(std::size_t n_threads, const Func& func) {
    std::vector<std::thread> threads;
    threads.reserve(n_threads);
    for (std::size_t thread_idx{}; thread_idx < n_threads; thread_idx++) {
        threads.emplace_back(func, thread_idx);
    }
    for (auto& thread : threads) {
        thread.join();
    }
}
} // namespace detail
\end{minted}
\caption{parallel\_for.hpp: Base function}
\label{lst:parallel_for_base_function}
\end{listing}

\begin{listing}[htb]
\begin{minted}[linenos, breaklines]{cpp}
template<typename Func>
requires detail::no_returnable<Func, std::size_t>
void parallel_for(std::size_t n_threads, std::size_t n_elements, Func&& func) {
    detail::parallel_for(
        n_threads,
        [n_threads, n_elements, func = std::forward<Func>(func)](
            std::size_t thread_idx) mutable {
            for (std::size_t i{thread_idx}; i < n_elements; i += n_threads) {
                func(i);
            }
        });
}

template<typename Func>
requires detail::returnable<Func, std::size_t>
auto parallel_for(std::size_t n_threads, std::size_t n_elements, Func&& func) {
    std::vector<std::invoke_result_t<Func, std::size_t>> result(n_elements);
    detail::parallel_for(
        n_threads,
        [n_threads, n_elements, func = std::forward<Func>(func), &result](
            std::size_t thread_idx) mutable {
            for (std::size_t i{thread_idx}; i < n_elements; i += n_threads) {
                result[i] = func(i);
            }
        });
    return result;
}
} // namespace mgr

#endif // JPEG2000_PARALLEL_FOR_HPP
\end{minted}
\caption{parallel\_for.hpp: User interface}
\label{lst:parallel_for_user_interface}
\end{listing}

\subsection{OpenCV}

% OpenCV (Open Source Computer Vision Library: http://opencv.org) is an open-source library that includes several hundreds of computer vision algorithms. The document describes the so-called OpenCV 2.x API, which is essentially a C++ API, as opposed to the C-based OpenCV 1.x API (C API is deprecated and not tested with "C" compiler since OpenCV 2.4 releases)

% OpenCV has a modular structure, which means that the package includes several shared or static libraries. The following modules are available:

% Core functionality (core) - a compact module defining basic data structures, including the dense multi-dimensional array Mat and basic functions used by all other modules.
% Image Processing (imgproc) - an image processing module that includes linear and non-linear image filtering, geometrical image transformations (resize, affine and perspective warping, generic table-based remapping), color space conversion, histograms, and so on.
% Video Analysis (video) - a video analysis module that includes motion estimation, background subtraction, and object tracking algorithms.
% Camera Calibration and 3D Reconstruction (calib3d) - basic multiple-view geometry algorithms, single and stereo camera calibration, object pose estimation, stereo correspondence algorithms, and elements of 3D reconstruction.
% 2D Features Framework (features2d) - salient feature detectors, descriptors, and descriptor matchers.
% Object Detection (objdetect) - detection of objects and instances of the predefined classes (for example, faces, eyes, mugs, people, cars, and so on).
% High-level GUI (highgui) - an easy-to-use interface to simple UI capabilities.
% Video I/O (videoio) - an easy-to-use interface to video capturing and video codecs.
% ... some other helper modules, such as FLANN and Google test wrappers, Python bindings, and others.
% The further chapters of the document describe functionality of each module. But first, make sure to get familiar with the common API concepts used thoroughly in the library.
